{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Openai GPT3\n",
    "\n",
    "Example how to generate conversations:\n",
    "https://beta.openai.com/docs/guides/completion/conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "engines = openai.Engine.list()['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ada', 'ada-code-search-code', 'ada-code-search-text', 'ada-instruct-beta', 'ada-search-document', 'ada-search-query', 'ada-similarity', 'babbage', 'babbage-code-search-code', 'babbage-code-search-text', 'babbage-instruct-beta', 'babbage-search-document', 'babbage-search-query', 'babbage-similarity', 'code-davinci-edit-001', 'code-search-ada-code-001', 'code-search-ada-text-001', 'code-search-babbage-code-001', 'code-search-babbage-text-001', 'curie', 'curie-instruct-beta', 'curie-instruct-beta-v2', 'curie-search-document', 'curie-search-query', 'curie-similarity', 'davinci', 'davinci-instruct-beta', 'davinci-instruct-beta-v3', 'davinci-search-document', 'davinci-search-query', 'davinci-similarity', 'text-ada-001', 'text-babbage-001', 'text-curie-001', 'text-davinci-001', 'text-davinci-002', 'text-davinci-edit-001', 'text-davinci-insert-001', 'text-davinci-insert-002', 'text-search-ada-doc-001', 'text-search-ada-query-001', 'text-search-babbage-doc-001', 'text-search-babbage-query-001', 'text-search-curie-doc-001', 'text-search-curie-query-001', 'text-search-davinci-doc-001', 'text-search-davinci-query-001', 'text-similarity-ada-001', 'text-similarity-babbage-001', 'text-similarity-curie-001', 'text-similarity-davinci-001']\n"
     ]
    }
   ],
   "source": [
    "print([engine['id'] for engine in engines])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "engines = {\n",
    "    'ada': 'text-ada-001',\n",
    "    'babbage': 'text-babbage-001',\n",
    "    'curie': 'text-curie-001',\n",
    "    'davinci': 'text-davinci-002'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Small example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prompt(animal):\n",
    "    return \"\"\"Suggest three names for an animal that is a superhero.\n",
    "Animal: Cat\n",
    "Names: Captain Sharpclaw, Agent Fluffball, The Incredible Feline\n",
    "Animal: Dog\n",
    "Names: Ruff the Protector, Wonder Canine, Sir Barks-a-Lot\n",
    "Animal: {}\n",
    "Names:\"\"\".format(\n",
    "        animal.capitalize()\n",
    "    )\n",
    "\n",
    "animal = 'Locust'\n",
    "# model = 'text-davinci-002'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject text_completion id=cmpl-4oVmNZ8XogUIUWj9KoqXkhxew9Bte at 0x1060f8450> JSON: {\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"finish_reason\": \"stop\",\n",
       "      \"index\": 0,\n",
       "      \"logprobs\": null,\n",
       "      \"text\": \" Swarm, Queen of the Swarm, The Great Locust\"\n",
       "    }\n",
       "  ],\n",
       "  \"created\": 1647943907,\n",
       "  \"id\": \"cmpl-4oVmNZ8XogUIUWj9KoqXkhxew9Bte\",\n",
       "  \"model\": \"text-curie:001\",\n",
       "  \"object\": \"text_completion\"\n",
       "}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = {\n",
    "    'restaurant': \"\"\"\n",
    "        The following is a conversation between a Human and a waiter called Artemis. The conversation takes place at a restaurant during lunch. The Human is about to order from Artemis. Artemis is very friendly, helpful and wants to help the Human have a nice lunch.\n",
    "\n",
    "        Artemis: Hi, my name is Artemis and I'll be your waiter today.\n",
    "        Human: Hi Artemis, nice to meet you.\n",
    "        \"\"\"\n",
    "}\n",
    "\n",
    "# model = 'text-curie-001'\n",
    "# model = 'text-babbage-001'\n",
    "model = 'text-ada-001'\n",
    "\n",
    "response = openai.Completion.create(\n",
    "            engine=model,\n",
    "            prompt=prompts['restaurant'],\n",
    "            temperature=0.6,\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject text_completion id=cmpl-4oYvykGiW1BSVNEKc2OOPyUf3ag00 at 0x101455b80> JSON: {\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"finish_reason\": \"length\",\n",
       "      \"index\": 0,\n",
       "      \"logprobs\": null,\n",
       "      \"text\": \" Artemis: And you're also welcome for lunch.\\n     \"\n",
       "    }\n",
       "  ],\n",
       "  \"created\": 1647956034,\n",
       "  \"id\": \"cmpl-4oYvykGiW1BSVNEKc2OOPyUf3ag00\",\n",
       "  \"model\": \"text-ada:001\",\n",
       "  \"object\": \"text_completion\"\n",
       "}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history = [\n",
    "    {\n",
    "        'sender': 'user',\n",
    "        'text': 'Hi, how are you?',\n",
    "        'error': False\n",
    "    },\n",
    "    {\n",
    "        'sender': 'bot',\n",
    "        'text': \"Thanks, I'm great. It's very nice to meet you.\"\n",
    "    },\n",
    "    {\n",
    "        'sender': 'user',\n",
    "        'text': \"How is the weather at your place?\"\n",
    "    }\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"User: Hi, how are you?\\nBot: Thanks, I'm great. It's very nice to meet you.\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for message in chat_history:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following is a conversation with an AI Language Teacher called Artemis. Artemis is helpful, funny, very friendly, and very good at teaching English. Artemis helps users to practice English by having conversations.\n",
      "User: Hi, how are you?\n",
      "Bot: Thanks, I'm great. It's very nice to meet you.\n",
      "User: How is the weather at your place?\n"
     ]
    }
   ],
   "source": [
    "def create_prompt(chat_history):\n",
    "    \" Convert the recent chat history to a prompt for GPT-3\"\n",
    "\n",
    "    prompt_base = \"\"\"The following is a conversation with an AI Language Teacher called Artemis. Artemis is helpful, funny, very friendly, and very good at teaching English. Artemis helps users to practice English by having conversations.\"\"\"\n",
    "\n",
    "    prompt_conv = \"\\n\".join([f\"{message['sender'].title()}: {message['text']}\" for message in chat_history])\n",
    "\n",
    "    prompt = \"\\n\".join([prompt_base, prompt_conv])\n",
    "    return prompt\n",
    "\n",
    "prompt = create_prompt(chat_history)\n",
    "print(prompt)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.Completion.create(\n",
    "            engine=model,\n",
    "            prompt=prompt,\n",
    "            temperature=0.6,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "reply = response['choices'][0]['text'].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"And you're also welcome for lunch.\""
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"It's good. How about you?\""
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_reply_text(prompt):\n",
    "    response = openai.Completion.create(\n",
    "            engine=model,\n",
    "            prompt=prompt,\n",
    "            temperature=0.5,\n",
    "        )\n",
    "    reply = None\n",
    "    if response and ('choices' in response) and len(response['choices']):\n",
    "        reply = response['choices'][0]['text'].strip()\n",
    "        # Get rid of \"Bot: \" at beginning of message\n",
    "        reply = \":\".join(reply.split(':')[1:]).strip()\n",
    "\n",
    "    return reply\n",
    "\n",
    "get_reply_text(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cc8015e61a03201b035b34b1113fcdaafe270f77fdb5ef38e87d79416051dc2f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('chatbot')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
