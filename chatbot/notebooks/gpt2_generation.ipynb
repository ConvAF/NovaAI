{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello\n"
     ]
    }
   ],
   "source": [
    "print(\"Hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chatbot\n",
    "\n",
    "from chatbot.db import get_db\n",
    "\n",
    "from chatbot.model import ModelBot\n",
    "\n",
    "bot = ModelBot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import GPT2Tokenizer, GPT2Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic (Headless) GPT 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "model = GPT2Model.from_pretrained('gpt2') # small\n",
    "# model = GPT2Model.from_pretrained('gpt2-md') # medium\n",
    "text = \"Replace me by any text you'd like.\"\n",
    "encoded_input = tokenizer(text, return_tensors='pt')\n",
    "output = model(**encoded_input)\n",
    "\n",
    "last_hidden_states = output.last_hidden_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPT 2 with Language Model\n",
    "\n",
    "Can generate text?\n",
    "https://huggingface.co/docs/transformers/model_doc/gpt2#transformers.GPT2LMHeadModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2', pad_token_id = tokenizer.eos_token_id)\n",
    "\n",
    "# tokenizer.decode(encoded_input[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode text\n",
    "# text = \"Sherlock Holmes was a famous detective who solved murder cases. He is most known for \"\n",
    "text = \"The tallest mountain in the world is \"\n",
    "\n",
    "encoded_input = tokenizer.encode(text, return_tensors='pt')\n",
    "\n",
    "output = model.generate(encoded_input, \n",
    "max_length = 10000, \n",
    "num_beams = 5,\n",
    "no_repeat_ngram_size  = 2,\n",
    "early_stopping = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tallest mountain in the world is Â Mount Everest. It is the highest mountain on the planet, and it is one of the most beautiful places on Earth. The mountain is also known as the \"Great Wall of China\" because of its sheer size and the fact that it was built on top of a mountain called the Great Wall, which is about the size of New York City.\n",
      "This is a great place to visit if you are looking for a beautiful view of Mt. Everest, or you just want to get a sense of what it's like to be in a place like this. If you have any questions or comments, feel free to leave a comment below or send me an email.<|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(output[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [3041, 5372, 502, 416, 597, 2420, 345, 1549, 588, 13], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokenizer(text, return_tensors='pt')\n",
    "tokenizer(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[3041, 5372,  502,  416,  597, 2420,  345, 1549,  588,   13]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_keys(['last_hidden_state', 'past_key_values'])\n"
     ]
    }
   ],
   "source": [
    "print(output.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.1629, -0.2166, -0.1410,  ..., -0.2619, -0.0819,  0.0092],\n",
       "         [ 0.4628,  0.0248, -0.0785,  ..., -0.0859,  0.5122, -0.3939],\n",
       "         [-0.0644,  0.1551, -0.6306,  ...,  0.2488,  0.3691,  0.0833],\n",
       "         ...,\n",
       "         [-0.5591, -0.4490, -1.4540,  ...,  0.1650, -0.1302, -0.3740],\n",
       "         [ 0.1400, -0.3875, -0.7916,  ..., -0.1780,  0.1824,  0.2185],\n",
       "         [ 0.1721, -0.2420, -0.1124,  ..., -0.1068,  0.1205, -0.3213]]],\n",
       "       grad_fn=<ViewBackward>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output['last_hidden_state']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'The White man worked as a clerk at the old'},\n",
       " {'generated_text': 'The White man worked as a salesman in Mexico and'},\n",
       " {'generated_text': 'The White man worked as a lawyer in the White'},\n",
       " {'generated_text': 'The White man worked as a clerk for the store'},\n",
       " {'generated_text': 'The White man worked as a barkeep and was'}]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline, set_seed\n",
    "generator = pipeline('text-generation', model='gpt2')\n",
    "set_seed(42)\n",
    "generator(\"The White man worked as a\", max_length=10, num_return_sequences=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "81e4e442e8f1a6312a7121210649192385821529460aee73e726d2e04cd8ba6e"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('ml-base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
