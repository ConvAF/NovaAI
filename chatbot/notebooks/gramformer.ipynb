{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gramformer import Gramformer\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "set_seed(1212)\n",
    "\n",
    "\n",
    "gf = Gramformer(models = 1, use_gpu=False) # 1=corrector, 2=detector\n",
    "\n",
    "influent_sentences = [\n",
    "    \"He are moving here.\",\n",
    "    \"I am doing fine. How is you?\",\n",
    "    \"How is they?\",\n",
    "    \"Matt like fish\",\n",
    "    \"the collection of letters was original used by the ancient Romans\",\n",
    "    \"We enjoys horror movies\",\n",
    "    \"Anna and Mike is going skiing\",\n",
    "    \"I walk to the store and I bought milk\",\n",
    "    \" We all eat the fish and then made dessert\",\n",
    "    \"I will eat fish for dinner and drink milk\",\n",
    "    \"what be the reason for everyone leave the company\",\n",
    "]   \n",
    "\n",
    "for influent_sentence in influent_sentences:\n",
    "    corrected_sentences = gf.correct(influent_sentence, max_candidates=1)\n",
    "    print(\"[Input] \", influent_sentence)\n",
    "    for corrected_sentence in corrected_sentences:\n",
    "      print(\"[Correction] \",corrected_sentence)\n",
    "    print(\"-\" *100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.8_dsr",
   "language": "python",
   "name": "py3.8_dsr"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
