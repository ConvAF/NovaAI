{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Collecting thefuzz\n",
      "  Downloading thefuzz-0.19.0-py2.py3-none-any.whl (17 kB)\n",
      "Installing collected packages: thefuzz\n",
      "Successfully installed thefuzz-0.19.0\n"
     ]
    }
   ],
   "source": [
    "#!pip install thefuzz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gramformer import Gramformer\n",
    "import torch\n",
    "import spacy\n",
    "import random\n",
    "from thefuzz import fuzz\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Original GrammarModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GrammarModel(Gramformer):\n",
    "    \"\"\"\n",
    "    Grammar correction model.\n",
    "    \"\"\"\n",
    "    def __init__(self, models=1, use_gpu=False, seed=1212):\n",
    "        self.gm = super().__init__(models=1, use_gpu=False)\n",
    "\n",
    "\n",
    "    def grammar_correction(self,last_user_input):\n",
    "        \"\"\"\n",
    "        Generate a corrected sentence and a message to the user with the correction.\n",
    "        \"\"\"\n",
    "        corrected_sentence = self.correct(last_user_input, max_candidates=1)\n",
    "        corrected_sentence = list(corrected_sentence)[0]\n",
    "        message_styles = [\n",
    "            \"I think you meant: \",\n",
    "            \"Oh, you mean: \",\n",
    "            \"This would be better said like this: \"\n",
    "        ]\n",
    "\n",
    "        if corrected_sentence != last_user_input:\n",
    "            correction_message = f\"{random.choice(message_styles)} \\\"{corrected_sentence}\\\" \"\n",
    "        else:\n",
    "             correction_message = None\n",
    "\n",
    "        return corrected_sentence, correction_message\n",
    "\n",
    "\n",
    "    def add_correction_to_chat_history(self, chat_history):\n",
    "        \"\"\"\n",
    "        Append the message to the user to the chat history.\n",
    "        Return the corrected sentence.\n",
    "        \"\"\"\n",
    "        last_user_input = chat_history[-1].get('text')\n",
    "        corrected_sentence, correction_message = self.grammar_correction(last_user_input)\n",
    "        error_types = self.get_edits(last_user_input, corrected_sentence)\n",
    "\n",
    "        if correction_message:\n",
    "            chat_history.append(\n",
    "                {\n",
    "                    'sender': 'bot',\n",
    "                    'text': correction_message,\n",
    "                    'correction': True\n",
    "                }\n",
    "            )\n",
    "        return chat_history       \n",
    "\n",
    "\n",
    "    def _get_edits(self, input_sentence, corrected_sentence):\n",
    "        \"\"\"\n",
    "        Return the type of the error.\n",
    "        \"\"\"\n",
    "        input_sentence = self.annotator.parse(input_sentence)\n",
    "        corrected_sentence = self.annotator.parse(corrected_sentence)\n",
    "        alignment = self.annotator.align(input_sentence, corrected_sentence)\n",
    "        edits = self.annotator.merge(alignment)\n",
    "\n",
    "        if len(edits) == 0:  \n",
    "            return []\n",
    "\n",
    "        edit_annotations = []\n",
    "        for e in edits:\n",
    "            e = self.annotator.classify(e)\n",
    "            edit_annotations.append(e.type[2:])\n",
    "                \n",
    "        if len(edit_annotations) > 0:\n",
    "            return edit_annotations\n",
    "        else:    \n",
    "            return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Gramformer] Grammar error correct/highlight model loaded..\n"
     ]
    }
   ],
   "source": [
    "gm = GrammarModel(models = 1, use_gpu=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Showcase punctuation and casing errors (GrammarModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example sentences\n",
    "ex1= \"Hi bot!\" # should not be corrected to \"Bot\"\n",
    "ex2= \"Hello\" # should not be corrected to \"Hello.\" or \"Hello!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_types_ex1 = []\n",
    "error_types_ex2 = []\n",
    "corrected_sentences_ex1 = []\n",
    "corrected_sentences_ex2 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello. ['OTHER']\n"
     ]
    }
   ],
   "source": [
    "correct_sentence, message = gm.grammar_correction(ex2)\n",
    "corrected_sentences_ex2.append(correct_sentence)\n",
    "\n",
    "error_types = gm.get_edits(ex2, correct_sentence)\n",
    "error_types_ex2.extend(error_types)\n",
    "\n",
    "print(correct_sentence, error_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: Hi bot!\n",
      "Error Types: ['OTHER', 'ORTH', 'OTHER', 'NOUN', 'OTHER', 'OTHER', 'ORTH']\n",
      "Suggested Corrections: ['Hi Bi-Bo!', 'Hi Bot!', 'Hi!', 'Hello BOTH!', 'Hi Bot!', 'Hi bot!']\n"
     ]
    }
   ],
   "source": [
    "# summary of tracked errors for sentence ex1\n",
    "print(f\"Original: {ex1}\\nError Types: {error_types_ex1}\\nSuggested Corrections: {corrected_sentences_ex1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: Hello\n",
      "Error Types: ['OTHER', 'OTHER', 'OTHER', 'OTHER', 'OTHER', 'OTHER']\n",
      "Suggested Corrections: ['Hello!', 'Hello.', 'Hello.', 'Hello.', 'Hello.', 'Hello.']\n"
     ]
    }
   ],
   "source": [
    "# summary of tracked errors for sentence ex2\n",
    "print(f\"Original: {ex2}\\nError Types: {error_types_ex2}\\nSuggested Corrections: {corrected_sentences_ex2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improvements to grammar correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GrammarModel2(Gramformer):\n",
    "    \"\"\"\n",
    "    Grammar correction model.\n",
    "    \"\"\"\n",
    "    def __init__(self, models=1, use_gpu=False, seed=1212):\n",
    "        self.gm = super().__init__(models=1, use_gpu=False)\n",
    "        self.ignore_errors = ['OTHER', 'ORTH']\n",
    "\n",
    "\n",
    "    def grammar_correction(self,last_user_input):\n",
    "        \"\"\"\n",
    "        Generate a corrected sentence and a message to the user with the correction.\n",
    "        \"\"\"\n",
    "        corrected_sentence = self.correct(last_user_input, max_candidates=1)\n",
    "        corrected_sentence = list(corrected_sentence)[0]\n",
    "        message_styles = [\n",
    "            \"I think you meant: \",\n",
    "            \"Oh, you mean: \",\n",
    "            \"This would be better said like this: \"\n",
    "        ]\n",
    "\n",
    "        if corrected_sentence != last_user_input:\n",
    "            correction_message = f\"{random.choice(message_styles)} \\\"{corrected_sentence}\\\" \"\n",
    "        else:\n",
    "             correction_message = None\n",
    "\n",
    "        return corrected_sentence, correction_message\n",
    "\n",
    "\n",
    "    def add_correction_to_chat_history(self, chat_history):\n",
    "        \"\"\"\n",
    "        Append the message to the user to the chat history.\n",
    "        Return the corrected sentence.\n",
    "        \"\"\"\n",
    "        last_user_input = chat_history[-1].get('text')\n",
    "        corrected_sentence, correction_message = self.grammar_correction(last_user_input)\n",
    "        error_types = self.get_edits(last_user_input, corrected_sentence)\n",
    "        relevant_error = any(error not in self.ignore_errors for error in error_types) # check if there is an error in the sentence which is not in the ignore list \n",
    "        token_sort_ratio = fuzz.token_sort_ratio(corrected_sentence, last_user_input) # calculate token similarity (ignoring punctuation and casing)\n",
    "        print(f\"correction_message: {correction_message}\\nErrors detected: {error_types}\\nPresence of a relevant error: {relevant_error}\\nSimilarity Score: {token_sort_ratio}\") # for debugging only\n",
    "        \n",
    "        if correction_message and relevant_error and token_sort_ratio != 100:\n",
    "            chat_history.append(\n",
    "                {\n",
    "                    'sender': 'bot',\n",
    "                    'text': correction_message,\n",
    "                    'correction': True\n",
    "                }\n",
    "            )\n",
    "        \n",
    "        return chat_history       \n",
    "\n",
    "\n",
    "    def _get_edits(self, input_sentence, corrected_sentence):\n",
    "        \"\"\"\n",
    "        Return the type of the error.\n",
    "        \"\"\"\n",
    "        input_sentence = self.annotator.parse(input_sentence)\n",
    "        corrected_sentence = self.annotator.parse(corrected_sentence)\n",
    "        alignment = self.annotator.align(input_sentence, corrected_sentence)\n",
    "        edits = self.annotator.merge(alignment)\n",
    "\n",
    "        if len(edits) == 0:  \n",
    "            return []\n",
    "\n",
    "        edit_annotations = []\n",
    "        for e in edits:\n",
    "            e = self.annotator.classify(e)\n",
    "            edit_annotations.append(e.type[2:])\n",
    "                \n",
    "        if len(edit_annotations) > 0:\n",
    "            return edit_annotations\n",
    "        else:    \n",
    "            return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Gramformer] Grammar error correct/highlight model loaded..\n"
     ]
    }
   ],
   "source": [
    "gm2 = GrammarModel2(models=1, use_gpu=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Remove correction when no relevant errors are detected(other than those in self.ignore_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history_ex1 = [{'sender': 'User', 'text': 'where are you goin?'}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correction_message: I think you meant:  \"where are you going?\" \n",
      "Errors detected: ['PUNCT']\n",
      "Presence of a relevant error: True\n",
      "Similarity Score: 97\n"
     ]
    }
   ],
   "source": [
    "chat_history = gm2.add_correction_to_chat_history(chat_history_ex1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'sender': 'User', 'text': 'where are you goin?'},\n",
       " {'sender': 'bot',\n",
       "  'text': 'I think you meant:  \"where are you going?\" ',\n",
       "  'correction': True}]"
      ]
     },
     "execution_count": 452,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Remove correction when input and correction are very similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of similar sentences which should not be corrected\n",
    "ex1 = \"Hi bot!\"\n",
    "ex2 = \"Hi bot\"\n",
    "ex3 = \"Hi bot.\"\n",
    "ex4 = \"Hi Bot\"\n",
    "ex5 = \"Hi Bot.\"\n",
    "ex6 = \"Hi Bot!\"\n",
    "ex7 = \"Hi Bot Bot!\" # should lead to lower token sort ratio, but same token set ratio compared to ex1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Measure the similarity between 0 and 100 to define a threshold.\n",
    "\n",
    "def measure_similarity(sentence1, sentence2):\n",
    "    simple_ratio = fuzz.ratio(sentence1, sentence2)\n",
    "    print(f\"simple ratio similarity score: {simple_ratio}\")\n",
    "\n",
    "    partial_ratio = fuzz.partial_ratio(sentence1, sentence2) # Return the ratio of the most similar substring.\n",
    "    print(f\"partial ratio similarity score: {partial_ratio}\")\n",
    "\n",
    "    ratio = fuzz.ratio(sentence1, sentence2)\n",
    "    print(f\"ratio similarity score: {ratio}\")\n",
    "\n",
    "    token_sort_ratio = fuzz.token_sort_ratio(sentence1, sentence2) # Return a measure of the sequences' similarity sorting the token before comparing. This is what we want to set as threshold.\n",
    "    print(f\"token sort ratio similarity score: {token_sort_ratio}\")\n",
    "\n",
    "    token_set_ratio = fuzz.token_set_ratio(sentence1, sentence2) # Measures similarity between unique tokens.\n",
    "    print(f\"token set ratio similarity score: {token_set_ratio}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "simple ratio similarity score: 67\n",
      "partial ratio similarity score: 71\n",
      "ratio similarity score: 67\n",
      "token sort ratio similarity score: 75\n",
      "token set ratio similarity score: 100\n"
     ]
    }
   ],
   "source": [
    "measure_similarity(ex1, ex7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Correction accuracy check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatbot",
   "language": "python",
   "name": "chatbot"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
